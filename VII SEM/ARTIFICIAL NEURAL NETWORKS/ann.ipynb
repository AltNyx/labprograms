{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ann.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRamCFt3rObExN4uLtvHyM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Il1pW000n3Nc","executionInfo":{"status":"ok","timestamp":1638764332516,"user_tz":-330,"elapsed":7,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"I8nxPGshp-0W","executionInfo":{"status":"ok","timestamp":1638764332516,"user_tz":-330,"elapsed":6,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}},"outputId":"3c7f24eb-3ff8-4b69-ad5e-c2a2fa0b965d"},"source":["# Defining network\n","input_layer_neurons = 2\n","hidden_layer_neurons = 3\n","output_layer_neurons = 1\n","\n","print(f\"Input layer neurons: {input_layer_neurons}\")\n","print(f\"Hidden layer neurons: {hidden_layer_neurons}\")\n","print(f\"Output layer neuron: {output_layer_neurons}\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Input layer neurons: 2\n","Hidden layer neurons: 3\n","Output layer neuron: 1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"mkvQbHb9q2Yv","executionInfo":{"status":"ok","timestamp":1638764332517,"user_tz":-330,"elapsed":6,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}},"outputId":"327f2e73-1d1c-4100-d06e-a5d5246cb565"},"source":["wh = np.random.uniform(size=(input_layer_neurons, hidden_layer_neurons))\n","bh = np.random.uniform(size=(1, hidden_layer_neurons))\n","wout = np.random.uniform(size=(hidden_layer_neurons, output_layer_neurons))\n","bout = np.random.uniform(size=(1, output_layer_neurons))\n","\n","print(f\"Weights from input layer to hidden layers: \\n{wh}\\n\")\n","print(f\"Bias in between input layer and hidden layers: \\n{bh}\\n\")\n","print(f\"Weights in between hidden layer and output layers: \\n{wout}\\n\")\n","print(f\"Bias in between hidden layer and output layers: \\n{bout}\\n\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights from input layer to hidden layers: \n","[[0.07665443 0.79617163 0.80714183]\n"," [0.32219442 0.97081914 0.8373135 ]]\n","\n","Bias in between input layer and hidden layers: \n","[[0.00789093 0.36282925 0.24478328]]\n","\n","Weights in between hidden layer and output layers: \n","[[0.0767625 ]\n"," [0.04666676]\n"," [0.89543769]]\n","\n","Bias in between hidden layer and output layers: \n","[[0.8736009]]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"H6E7HIzTsDss","executionInfo":{"status":"ok","timestamp":1638764332517,"user_tz":-330,"elapsed":5,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}},"outputId":"b4368f4d-172b-4cf8-98f3-edf66bc99ece"},"source":["# Initializaion\n","epoch = 7000 # Training iterations\n","learning_rate = 0.1\n","\n","# Inputs\n","X = np.array([[2, 9], [1, 5], [3, 6]], dtype=float)\n","\n","# Outputs\n","y = np.array([[1], [0], [1]], dtype=float)\n","\n","# Normalizing inputs\n","X = X/np.amax(X, axis=0)\n","X"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.66666667, 1.        ],\n","       [0.33333333, 0.55555556],\n","       [1.        , 0.66666667]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"YPtihqFxsj3P","executionInfo":{"status":"ok","timestamp":1638764332517,"user_tz":-330,"elapsed":4,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}}},"source":["def sigmoid(x):\n","    return 1/(1 + np.exp(-x))\n","\n","def derivatives_sigmoid(x):\n","    return x*(1-x)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0rePb774tMpS","executionInfo":{"status":"ok","timestamp":1638764332932,"user_tz":-330,"elapsed":418,"user":{"displayName":"V ABHISHEK KUMAR","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16275495976949385743"}},"outputId":"1e96d857-785a-4144-b07f-999a85ce60af"},"source":["# Forward propgation\n","for i in range(epoch):\n","    h_activation = sigmoid(np.dot(X, wh) + bh)\n","    output = sigmoid(np.dot(h_activation, wout) + bout)\n","\n","    # Backpropogation\n","    e_out = y-output # Error at output layer\n","    output_gradient = derivatives_sigmoid(output) # Error portion at output layer\n","    d_output = e_out*output_gradient\n","\n","    e_hidden = d_output.dot(wout.T)\n","    hidden_gradient = derivatives_sigmoid(h_activation)\n","    d_hidden = e_hidden*hidden_gradient\n","\n","    wout += h_activation.T.dot(d_output) * learning_rate # Each hidden layer output value * final output layer\n","    wh += X.T.dot(d_hidden) * learning_rate # change weights between input layer and hidden layer\n","\n","print(f\"Input: \\n {X}\\n\")\n","print(f\"Actual Output: \\n{y}\\n\")\n","print(f\"Predicted Output: \\n{output}\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: \n"," [[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","\n","Actual Output: \n","[[1.]\n"," [0.]\n"," [1.]]\n","\n","Predicted Output: \n","[[0.76031744]\n"," [0.26033622]\n"," [0.95134958]]\n"]}]}]}